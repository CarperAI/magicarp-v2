model:
  model_path: "roberta-base"
  tokenizer_path: "roberta-base"
  sequence_length: 1024

train:
  learning_rate: 1.0e-4
  batch_size: 4

